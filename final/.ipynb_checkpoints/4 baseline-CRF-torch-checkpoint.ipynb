{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dc33edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.metrics import classification_report, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#from torch_model_base import TorchModelBase\n",
    "#from torch_shallow_neural_classifier import TorchShallowNeuralClassifier\n",
    "from torch_rnn_classifier import TorchRNNDataset, TorchRNNClassifier, TorchRNNModel\n",
    "import utils\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import json\n",
    "\n",
    "from torchcrf import CRF\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bed4b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('annotations2.jsonl') as jsonl_file:\n",
    "    # note: after running data-preprocessing.ipynb this file already has token-level labels\n",
    "    lines = jsonl_file.readlines()\n",
    "annot = [json.loads(line) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "586f79a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get data into two separate list of lists:\n",
    "X=[] \n",
    "y=[]\n",
    "for j in range(0,len(annot)):\n",
    "    a = annot[j]['tokens']\n",
    "    auxX = []\n",
    "    auxy = []\n",
    "    if annot[j]['spans']!=[]: # are there annot for this example?\n",
    "        for i in range(0,len(a)):\n",
    "            #token_element = (a[i]['text'],a[i]['label'])\n",
    "            auxX.append(a[i]['text'])\n",
    "            auxy.append(a[i]['label'])\n",
    "        X.append(auxX)\n",
    "        y.append(auxy)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "#X_train, X_test, y_train, y_test = X[:120], X[120:], y[:120], y[120:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "840cd5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create word to id dictionary\n",
    "word_to_ix = {}\n",
    "for sentence in X:\n",
    "    for word in sentence:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix) # i.e. each successive word added gets a successive index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67631472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create label to id dictionary\n",
    "label_to_ix = {}\n",
    "for sentence in y:\n",
    "    for label in sentence:\n",
    "        if label not in label_to_ix:\n",
    "            label_to_ix[label] = len(label_to_ix) # i.e. each successive word added gets a successive index\n",
    "\n",
    "# and id to label dictionary also:\n",
    "ix_to_label = {label_to_ix[item]:item for item in label_to_ix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "397564ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dicts to convert X and y to indices (ints)\n",
    "X_ix = [[word_to_ix[w] for w in seq] for seq in X]\n",
    "y_ix = [[label_to_ix[l] for l in seq] for seq in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e444a27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.75\n",
    "train_test_split = round(0.75*len(X) - 0.5) # -0.5 => floor\n",
    "\n",
    "# next 3 lines guarantee we always use same random indices for train / test set\n",
    "idx_shuffle=pd.read_csv('idx_shuffle.csv') \n",
    "auxIdxList = idx_shuffle.values.tolist()\n",
    "idx_shuffle = [el for auxList in auxIdxList for el in auxList]\n",
    "X_shuffle, y_shuffle = [X[auxIdx] for auxIdx in idx_shuffle], [y[auxIdx] for auxIdx in idx_shuffle]\n",
    "X_train, X_test, y_train, y_test = X_shuffle[:train_test_split], X_shuffle[train_test_split:], y_shuffle[:train_test_split], y_shuffle[train_test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d476f423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94, 130, 26, 8, 30, 92, 110, 101, 44, 104, 66, 100, 43, 97, 22, 116, 96, 89, 7, 24, 62, 10, 109, 45, 16, 2, 59, 129, 107, 125, 33, 68, 56, 85, 126, 13, 51, 84, 54, 50, 15, 61, 40, 76, 52, 3, 48, 6, 71, 60, 105, 122, 119, 99, 63, 93, 108, 27, 18, 113, 11, 111, 73, 127, 98, 41, 90, 1, 86, 118, 42, 4, 17, 38, 5, 53, 124, 78, 0, 34, 28, 55, 75, 35, 23, 74, 31, 91, 57, 106, 131, 32, 115, 14, 95, 19, 29, 49, 112, 82, 64, 132, 79, 69, 80, 20, 128, 72, 77, 25, 37, 81, 120, 46, 123, 39, 102, 65, 58, 12, 121, 88, 70, 87, 36, 114, 21, 83, 9, 103, 67, 117, 47]\n"
     ]
    }
   ],
   "source": [
    "print(idx_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeb8e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted({y for auxVec in y_train for y in auxVec})\n",
    "numTags = len(labels)\n",
    "seq_lengths = [len(auxVec) for auxVec in X_train] # note: want to create mask only for inputs we're going to use to train the model\n",
    "seq_length_max = max(seq_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "140c67c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(seq_length):\n",
    "    maxLen=max(seq_length)\n",
    "    auxLen=len(seq_length)\n",
    "    auxOne = torch.ones(maxLen)\n",
    "    auxZero = torch.zeros(maxLen)\n",
    "    auxOne_l=[1]*maxLen\n",
    "    auxZero_l=[0]*maxLen\n",
    "    auxMatrix=[]\n",
    "    for i in range(auxLen):\n",
    "        auxRow=auxOne_l[:seq_length[i]]+auxZero_l[seq_length[i]:]\n",
    "        auxMatrix.append(auxRow)\n",
    "    return torch.tensor(auxMatrix,dtype=torch.uint8)  \n",
    "\n",
    "def fillList_ofLists(y):\n",
    "    auxMatrix = []\n",
    "    seq_length_max = max([len(auxVec) for auxVec in y])\n",
    "    for i in range(0,len(y)):\n",
    "        auxRow=y[i]+[-1]*(seq_length_max-len(y[i])) # -1 is the tagId I'm using for the filled data\n",
    "        auxMatrix.append(auxRow)\n",
    "    return auxMatrix \n",
    "\n",
    "def convert_to_Tensor_andStack(y_train_forCRF):\n",
    "    auxMatrix = torch.tensor(y_train_forCRF[0])\n",
    "    for i in range(1,len(y_train_forCRF)):\n",
    "        auxMatrix = torch.vstack((auxMatrix,torch.tensor(y_train_forCRF[i])))\n",
    "    return auxMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95ef1ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = create_mask(seq_lengths) # this is mask for CRF model\n",
    "X_train_forCRF = fillList_ofLists(X_train) # tags filled out and converted to tensor\n",
    "y_train_forCRF = fillList_ofLists(y_train) # tags filled out and converted to tensor\n",
    "tags = convert_to_Tensor_andStack(y_train_forCRF) # these are tags for CRF mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f505cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: calc emission probabilities. dim = (noExamples,maxSeqLength,noDistinctTags) (incl bogus tag used for padding)\n",
    "# represents prob of each word in sequence being emitted by a given tag/label\n",
    "# (naiive emissions calc - i.e. no more sophisticated notions of word embeddings or neighbour information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12d09a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create dict of (wordId,tagId); value=no. of co-occurrences\n",
    "def convertList_ofLists_bivariate(X_train,y_train): #stitches together 2 separate list of lists w/ identical lengths\n",
    "    auxMatrix=[]\n",
    "    for i in range(0,len(X_train)):\n",
    "        auxRow=list(zip(X_train[i],y_train[i]))\n",
    "        auxMatrix.append(auxRow)\n",
    "    return auxMatrix\n",
    "\n",
    "def emissionProbabilities(X_input, y_input): # X_input and y_input are list of (equal-length) lists - i.e. after padding; dim=(noExamples,maxSeqLength)\n",
    "    allData_train = convertList_ofLists_bivariate(X_input,y_input)\n",
    "    allData_countDict = Counter([auxItem for auxVec in allData_train for auxItem in auxVec]) # dict of (wordId,tagId); value=no. of co-occurrences\n",
    "\n",
    "    # obtain counts of each tag:\n",
    "    y_countDic = Counter([auxY for seq in y_input for auxY in seq]) # key=labelId; value = # of x's labeId shows up\n",
    "    # now convert into emission probabilities of each pair (wordId,tagId) i.e. prob that word is emitted by a given tag\n",
    "    allData_prob = {} # dict for emission probabilities of (wordId,tagId)\n",
    "    for item in allData_countDict:\n",
    "        if item==(-1,-1): \n",
    "            allData_prob[item]=0\n",
    "        else:\n",
    "            wordId,tagId = item\n",
    "            allData_prob[item]=allData_countDict[item]/y_countDic[tagId]\n",
    "    return allData_prob\n",
    "\n",
    "def emissionMatrix_forCRF(X_input, labels, emissionProbs): # X_input is list of (equal-length) lists - i.e. after padding; dim=(noExamples,maxSeqLength)\n",
    "    # labels is list of distinct labels; emissionProbs is dict of prob word i is emitted by label/tag j\n",
    "    # now use above emission prob (wordId,tagId) as lookup for emission prob of seq i: for all wordId's in position j of seq_i and all tagId's populate w/ emission prob        \n",
    "    nExamples = len(X_input)\n",
    "    seq_length_max = len(X_input[0])\n",
    "    labels_aux = labels + [-1] # add bogus tag for padded data\n",
    "    nLabels_aux=len(labels_aux)\n",
    "    emiss=torch.zeros(nExamples,seq_length_max,nLabels_aux)\n",
    "    for i in range(0,nExamples):\n",
    "        auxSeq = X_input[i]\n",
    "        for j in range(0,seq_length_max):\n",
    "            for k in range(0,nLabels_aux):\n",
    "                if (auxSeq[j],labels_aux[k]) in emissionProbs: # note: if certain combination doesn't exist then leave with zero\n",
    "                    emiss[i][j][k]=emissionProbs[(auxSeq[j],labels_aux[k])]\n",
    "    return emiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff7bdb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "allData_prob = emissionProbabilities(X_train_forCRF,y_train_forCRF)\n",
    "emiss = emissionMatrix_forCRF(X_train_forCRF,labels,allData_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6743f530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-13403.5869, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# RUN CRF MODEL\n",
    "torch.manual_seed(1)\n",
    "#seq_length_max = 3  # maximum sequence length in a batch\n",
    "batch_size = train_test_split  # number of samples in the batch\n",
    "model = CRF(numTags+1,batch_first=True)\n",
    "\n",
    "#emissions = torch.randn(batch_size, seq_length_max, num_tags)\n",
    "print(model(emiss, tags, mask=mask)) # model log likelihood\n",
    "out=model.decode(emiss,mask=mask) # most likely tag sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d1ccd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now convert out (and y_train) back to text labels       \n",
    "labels_text = [ix_to_label[label] for label in labels]\n",
    "y_test_text = [[ix_to_label[item] for item in auxOut] for auxOut in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f9eb1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now need to calc emissions of X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b26d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lengths_test = [len(auxVec) for auxVec in X_test]\n",
    "mask_test = create_mask(seq_lengths_test) # this is mask for CRF model\n",
    "X_test_forCRF = fillList_ofLists(X_test) # tags filled out and converted to tensor\n",
    "emiss_test = emissionMatrix_forCRF(X_test_forCRF,labels,allData_prob) # use emission probabities from training data (allData_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "546d40ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_test=model.decode(emiss_test,mask=mask_test) # most likely tag sequences\n",
    "out_test_text=[[ix_to_label[item] for item in auxOut] for auxOut in out_test]# convert out_test to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1f32381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25206892079328913\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_f1_score(y_test_text, out_test_text,average='macro', labels=labels_text))\n",
    "print(metrics.sequence_accuracy_score(y_test_text, out_test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82c92387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                ORT      0.920     0.390     0.548        59\n",
      "                  O      0.836     0.850     0.843      1525\n",
      "            STRASSE      0.157     0.318     0.211        44\n",
      "            FLAECHE      0.000     0.000     0.000        38\n",
      "           IMMO_TYP      0.522     0.511     0.516        47\n",
      "            QMPREIS      0.000     0.000     0.000        21\n",
      "   TERRASSENGROESSE      0.011     0.125     0.019         8\n",
      "            KAEUFER      0.250     0.030     0.054        33\n",
      "         VERKAEUFER      0.375     0.290     0.327        62\n",
      "        GESAMTPREIS      0.045     0.034     0.039        29\n",
      "      DATUM_VERTRAG      0.000     0.000     0.000        62\n",
      "DATUM_VERBUECHERUNG      0.481     0.455     0.467        55\n",
      "\n",
      "           accuracy                          0.708      1983\n",
      "          macro avg      0.300     0.250     0.252      1983\n",
      "       weighted avg      0.716     0.708     0.706      1983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_classification_report(\n",
    "    y_test_text, out_test_text, labels=labels_text, digits=3\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
