{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "758a94ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instances:\n",
      "140\n",
      "\n",
      "all keys:\n",
      "['text', 'meta', '_input_hash', '_task_hash', 'spans', 'tokens', '_view_id', 'answer', '_timestamp']\n",
      "\n",
      "important keys:\n",
      "['text', 'spans', 'tokens']\n",
      "\n",
      "example text:\n",
      "DORNBIRN In der Schulgasse in Dornbirn hat eine 71,93 Quadratmeter große Wohnung für einen Quadratmeterpreis von 5533,71 Euro den Besitzer gewechselt. Dieser beinhaltet auch einen Pkw-Abstellplatz. Käufer der Wohnung mit 9,86 Quadratmetern Terrasse ist die ValLiLean Beteiligungs- und Immobilienverwaltungs GmbH. Beim Verkäufer handelt es sich um die Karrenblick Projekt GmbH.  Der Kaufpreis liegt bei 398.040 Euro. Unterzeichnet wurde der Kaufvertrag am 18. September. Die Verbücherung datiert mit Oktober 2020.\n",
      "\n",
      "5 example spans:\n",
      "{'text': 'DORNBIRN', 'start': 0, 'end': 8, 'pattern': 2069086582, 'token_start': 0, 'token_end': 0, 'label': 'ORT', 'noWords': 1}\n",
      "{'start': 16, 'end': 26, 'token_start': 3, 'token_end': 3, 'label': 'STRASSE', 'noWords': 1}\n",
      "{'text': 'Dornbirn', 'start': 30, 'end': 38, 'pattern': 2069086582, 'token_start': 5, 'token_end': 5, 'label': 'ORT', 'noWords': 1}\n",
      "{'start': 48, 'end': 53, 'token_start': 8, 'token_end': 8, 'label': 'FLAECHE', 'noWords': 1}\n",
      "{'start': 73, 'end': 80, 'token_start': 11, 'token_end': 11, 'label': 'IMMO_TYP', 'noWords': 1}\n",
      "\n",
      "5 example tokens:\n",
      "{'text': 'DORNBIRN', 'start': 0, 'end': 8, 'id': 0, 'ws': True, 'label': 'ORT'}\n",
      "{'text': 'In', 'start': 9, 'end': 11, 'id': 1, 'ws': True, 'label': 'O'}\n",
      "{'text': 'der', 'start': 12, 'end': 15, 'id': 2, 'ws': True, 'label': 'O'}\n",
      "{'text': 'Schulgasse', 'start': 16, 'end': 26, 'id': 3, 'ws': True, 'label': 'STRASSE'}\n",
      "{'text': 'in', 'start': 27, 'end': 29, 'id': 4, 'ws': True, 'label': 'O'}\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "#import sklearn\n",
    "#import sklearn_crfsuite\n",
    "#from sklearn_crfsuite import scorers\n",
    "#from sklearn.utils import shuffle\n",
    "#from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "#from sklearn_crfsuite import metrics\n",
    "#from sklearn.metrics import make_scorer\n",
    "#import metrics as mtx\n",
    "#import scipy.stats\n",
    "#import random\n",
    "import json\n",
    "from datasets import Dataset\n",
    "\n",
    "with open(\"./annotations2.jsonl\") as jsonl_file: # . instead of ..\n",
    "    lines = jsonl_file.readlines()\n",
    "annot = [json.loads(line) for line in lines]\n",
    "print(\"instances:\\n{}\".format(len(annot)))\n",
    "keys = [key for key in annot[0].keys()]\n",
    "print(\"\\nall keys:\\n{}\".format(keys))\n",
    "key_keys = [\"text\", \"spans\", \"tokens\"]\n",
    "print(\"\\nimportant keys:\\n{}\".format(key_keys))\n",
    "print(\"\\nexample text:\\n{}\".format(annot[0][\"text\"]))\n",
    "n_examples = 5\n",
    "print(\"\\n{} example spans:\".format(n_examples))\n",
    "for span in annot[0][\"spans\"][:n_examples]:\n",
    "    print(\"{}\".format(span))\n",
    "print(\"\\n{} example tokens:\".format(n_examples))\n",
    "for token in annot[0][\"tokens\"][:n_examples]:\n",
    "    print(\"{}\".format(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc53d613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token dictionaries for the last 3 words of instance 0\n",
      "{'text': 'DORNBIRN', 'start': 0, 'end': 8, 'id': 0, 'ws': True, 'label': 'ORT'}\n",
      "{'text': 'In', 'start': 9, 'end': 11, 'id': 1, 'ws': True, 'label': 'O'}\n",
      "{'text': 'der', 'start': 12, 'end': 15, 'id': 2, 'ws': True, 'label': 'O'}\n",
      "Token dictionaries for the last 3 words of instance 1\n",
      "{'text': 'FELDKIRCH', 'start': 0, 'end': 9, 'id': 0, 'ws': True, 'label': 'ORT'}\n",
      "{'text': 'Im', 'start': 10, 'end': 12, 'id': 1, 'ws': True, 'label': 'O'}\n",
      "{'text': 'Altenreuteweg', 'start': 13, 'end': 26, 'id': 2, 'ws': True, 'label': 'STRASSE'}\n"
     ]
    }
   ],
   "source": [
    "def getLabel(tokenDictList, idx):\n",
    "    result = \"O\"\n",
    "    for dict_i in tokenDictList:\n",
    "        idx_0, idx_1 = dict_i[\"start\"], dict_i[\"end\"]\n",
    "        if (idx_0<=idx) and (idx<=idx_1):\n",
    "            result = dict_i[\"label\"]\n",
    "    return result \n",
    "\n",
    "for j in range(len(annot)): # loop over instances\n",
    "    a = annot[j]            # instance j\n",
    "    spans = a[\"spans\"]      # list of annotation dicts\n",
    "    toks = a[\"tokens\"]      # list of token dicts\n",
    "    for i in range(len(toks)):                                 # loop over token dicts\n",
    "        toks[i][\"label\"] = getLabel(spans, toks[i][\"start\"])   # assign label from span (if exists, otherwise \"O\")\n",
    "    annot[j][\"tokens\"] = toks\n",
    "\n",
    "words_n = 3\n",
    "for i in range(2):\n",
    "    print(\"Token dictionaries for the last {} words of instance {}\".format(words_n, i))\n",
    "    ann = annot[i]\n",
    "    for tok in ann[\"tokens\"][:words_n]:\n",
    "        print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e587b7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('DORNBIRN', 'ORT'),\n",
       "  ('In', 'O'),\n",
       "  ('der', 'O'),\n",
       "  ('Schulgasse', 'STRASSE'),\n",
       "  ('in', 'O'),\n",
       "  ('Dornbirn', 'ORT'),\n",
       "  ('hat', 'O'),\n",
       "  ('eine', 'O'),\n",
       "  ('71,93', 'FLAECHE'),\n",
       "  ('Quadratmeter', 'O'),\n",
       "  ('große', 'O'),\n",
       "  ('Wohnung', 'IMMO_TYP'),\n",
       "  ('für', 'O'),\n",
       "  ('einen', 'O'),\n",
       "  ('Quadratmeterpreis', 'O'),\n",
       "  ('von', 'O'),\n",
       "  ('5533,71', 'QMPREIS'),\n",
       "  ('Euro', 'O'),\n",
       "  ('den', 'O'),\n",
       "  ('Besitzer', 'O'),\n",
       "  ('gewechselt', 'O'),\n",
       "  ('.', 'O'),\n",
       "  ('Dieser', 'O'),\n",
       "  ('beinhaltet', 'O'),\n",
       "  ('auch', 'O'),\n",
       "  ('einen', 'O'),\n",
       "  ('Pkw-Abstellplatz', 'O'),\n",
       "  ('.', 'O'),\n",
       "  ('Käufer', 'O'),\n",
       "  ('der', 'O'),\n",
       "  ('Wohnung', 'O'),\n",
       "  ('mit', 'O'),\n",
       "  ('9,86', 'TERRASSENGROESSE'),\n",
       "  ('Quadratmetern', 'O'),\n",
       "  ('Terrasse', 'O'),\n",
       "  ('ist', 'O'),\n",
       "  ('die', 'O'),\n",
       "  ('ValLiLean', 'KAEUFER'),\n",
       "  ('Beteiligungs-', 'KAEUFER'),\n",
       "  ('und', 'KAEUFER'),\n",
       "  ('Immobilienverwaltungs', 'KAEUFER'),\n",
       "  ('GmbH', 'KAEUFER'),\n",
       "  ('.', 'KAEUFER'),\n",
       "  ('Beim', 'O'),\n",
       "  ('Verkäufer', 'O'),\n",
       "  ('handelt', 'O'),\n",
       "  ('es', 'O'),\n",
       "  ('sich', 'O'),\n",
       "  ('um', 'O'),\n",
       "  ('die', 'O'),\n",
       "  ('Karrenblick', 'VERKAEUFER'),\n",
       "  ('Projekt', 'VERKAEUFER'),\n",
       "  ('GmbH', 'VERKAEUFER'),\n",
       "  ('.', 'VERKAEUFER'),\n",
       "  (' ', 'O'),\n",
       "  ('Der', 'O'),\n",
       "  ('Kaufpreis', 'O'),\n",
       "  ('liegt', 'O'),\n",
       "  ('bei', 'O'),\n",
       "  ('398.040', 'GESAMTPREIS'),\n",
       "  ('Euro', 'O'),\n",
       "  ('.', 'O'),\n",
       "  ('Unterzeichnet', 'O'),\n",
       "  ('wurde', 'O'),\n",
       "  ('der', 'O'),\n",
       "  ('Kaufvertrag', 'O'),\n",
       "  ('am', 'O'),\n",
       "  ('18.', 'DATUM_VERTRAG'),\n",
       "  ('September', 'DATUM_VERTRAG'),\n",
       "  ('.', 'DATUM_VERTRAG'),\n",
       "  ('Die', 'O'),\n",
       "  ('Verbücherung', 'O'),\n",
       "  ('datiert', 'O'),\n",
       "  ('mit', 'O'),\n",
       "  ('Oktober', 'DATUM_VERBUECHERUNG'),\n",
       "  ('2020', 'DATUM_VERBUECHERUNG'),\n",
       "  ('.', 'DATUM_VERBUECHERUNG')],\n",
       " [('FELDKIRCH', 'ORT'),\n",
       "  ('Im', 'O'),\n",
       "  ('Altenreuteweg', 'STRASSE'),\n",
       "  ('in', 'O'),\n",
       "  ('Feldkirch', 'ORT'),\n",
       "  ('hat', 'O'),\n",
       "  ('eine', 'O'),\n",
       "  ('100,67', 'FLAECHE'),\n",
       "  ('Quadratmeter', 'O'),\n",
       "  ('große', 'O'),\n",
       "  ('Wohnung', 'IMMO_TYP'),\n",
       "  ('für', 'O'),\n",
       "  ('einen', 'O'),\n",
       "  ('Quadratmeterpreis', 'O'),\n",
       "  ('von', 'O'),\n",
       "  ('6168,67', 'QMPREIS'),\n",
       "  ('Euro', 'O'),\n",
       "  ('den', 'O'),\n",
       "  ('Besitzer', 'O'),\n",
       "  ('gewechselt', 'O'),\n",
       "  ('.', 'O'),\n",
       "  ('Käufer', 'O'),\n",
       "  ('der', 'O'),\n",
       "  ('Wohnung', 'O'),\n",
       "  ('mit', 'O'),\n",
       "  ('einer', 'O'),\n",
       "  ('137,49', 'TERRASSENGROESSE'),\n",
       "  ('Quadratmeter', 'O'),\n",
       "  ('großen', 'O'),\n",
       "  ('Terrasse', 'O'),\n",
       "  ('ist', 'O'),\n",
       "  ('eine', 'O'),\n",
       "  ('Privatperson', 'KAEUFER'),\n",
       "  ('.', 'KAEUFER'),\n",
       "  ('Beim', 'O'),\n",
       "  ('Verkäufer', 'O'),\n",
       "  ('handelt', 'O'),\n",
       "  ('es', 'O'),\n",
       "  ('sich', 'O'),\n",
       "  ('um', 'O'),\n",
       "  ('die', 'O'),\n",
       "  ('Rüscher', 'VERKAEUFER'),\n",
       "  ('und', 'VERKAEUFER'),\n",
       "  ('Söhne', 'VERKAEUFER'),\n",
       "  ('Bau', 'VERKAEUFER'),\n",
       "  ('GmbH', 'VERKAEUFER'),\n",
       "  ('&', 'VERKAEUFER'),\n",
       "  ('Co', 'VERKAEUFER'),\n",
       "  ('KG', 'VERKAEUFER'),\n",
       "  ('.', 'VERKAEUFER'),\n",
       "  (' ', 'O'),\n",
       "  ('Der', 'O'),\n",
       "  ('Kaufpreis', 'O'),\n",
       "  ('liegt', 'O'),\n",
       "  ('bei', 'O'),\n",
       "  ('621.000', 'GESAMTPREIS'),\n",
       "  ('Euro', 'O'),\n",
       "  ('.', 'O'),\n",
       "  ('Unterzeichnet', 'O'),\n",
       "  ('wurde', 'O'),\n",
       "  ('der', 'O'),\n",
       "  ('Kaufvertrag', 'O'),\n",
       "  ('am', 'O'),\n",
       "  ('11.', 'DATUM_VERTRAG'),\n",
       "  ('August', 'DATUM_VERTRAG'),\n",
       "  ('.', 'DATUM_VERTRAG'),\n",
       "  ('Die', 'O'),\n",
       "  ('Verbücherung', 'O'),\n",
       "  ('datiert', 'O'),\n",
       "  ('mit', 'O'),\n",
       "  ('September', 'DATUM_VERBUECHERUNG'),\n",
       "  ('2020', 'DATUM_VERBUECHERUNG'),\n",
       "  ('.', 'DATUM_VERBUECHERUNG')]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents=[] \n",
    "for annot_i in annot:                  # loop over instances\n",
    "    toks = annot_i['tokens']           # get tokens list for instance i\n",
    "    train_sentence = []\n",
    "    for tok in toks:                   # loop over token dicts\n",
    "        if 'label' in tok:             # only if the current token has been labelled, ...\n",
    "            token_element = (tok['text'], tok['label']) # ... create a \"text\", \"label\" pair for this token ...\n",
    "            train_sentence.append(token_element)        # ... and append it to the list\n",
    "    sents.append(train_sentence) # append the list for that instances to the list for all instances / sentences\n",
    "\n",
    "# list of lists of pairs (sets): outer list contains instances and inner list contains (token, label) pairs\n",
    "sents[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec2593d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'labels'],\n",
       "    num_rows: 140\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. build tokens = list of lists of tokens\n",
    "# 2. build labels = list of lists of labels\n",
    "tokens = []\n",
    "labels = []\n",
    "for sent_i in sents:\n",
    "    tokens_i = []\n",
    "    labels_i = []\n",
    "    for word_label in sent_i:\n",
    "        tokens_i.append(word_label[0])\n",
    "        labels_i.append(word_label[1])\n",
    "    tokens.append(tokens_i)\n",
    "    labels.append(labels_i)\n",
    "\n",
    "dataset = Dataset.from_dict({\"tokens\": tokens, \"labels\": labels})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8287f437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DATUM_VERBUECHERUNG',\n",
       " 'DATUM_VERTRAG',\n",
       " 'FLAECHE',\n",
       " 'GESAMTPREIS',\n",
       " 'IMMO_TYP',\n",
       " 'KAEUFER',\n",
       " 'O',\n",
       " 'ORT',\n",
       " 'QMPREIS',\n",
       " 'STRASSE',\n",
       " 'TERRASSENGROESSE',\n",
       " 'VERKAEUFER']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set of labels\n",
    "label_names = sorted(list(set([label_ij for labels_i in labels for label_ij in labels_i])))\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b91604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'labels': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0326e130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
    "ner_feature = dataset.features[\"tokens\"]\n",
    "ner_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b02670f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(num_classes=12, names=['DATUM_VERBUECHERUNG', 'DATUM_VERTRAG', 'FLAECHE', 'GESAMTPREIS', 'IMMO_TYP', 'KAEUFER', 'O', 'ORT', 'QMPREIS', 'STRASSE', 'TERRASSENGROESSE', 'VERKAEUFER'], id=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset.features[\"tokens\"].feature.names = label_names # ClassLabel(names=label_names)\n",
    "from datasets import ClassLabel\n",
    "dataset.features[\"tokens\"].feature.names = ClassLabel(names=label_names)\n",
    "dataset.features[\"tokens\"].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11feed58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize and adjust labels\n",
    "checkpoint = \"flair/ner-german\"  # https://huggingface.co/flair/ner-german\n",
    "checkpoint = \"fhswf/bert_de_ner\" # https://huggingface.co/fhswf/bert_de_ner\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "982f1106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'labels'],\n",
       "    num_rows: 140\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dfa0f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
    "#inputs.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cdffac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 17,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 33,\n",
       " 33,\n",
       " 34,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 51,\n",
       " 51,\n",
       " 52,\n",
       " 52,\n",
       " 52,\n",
       " 53,\n",
       " 55,\n",
       " 56,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 60,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 67,\n",
       " 68,\n",
       " 68,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 71,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " None]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(dataset[0][\"tokens\"], is_split_into_words=True)\n",
    "inputs.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02d4629a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'dor',\n",
       " '##nb',\n",
       " '##irn',\n",
       " 'in',\n",
       " 'der',\n",
       " 'schul',\n",
       " '##gasse',\n",
       " 'in',\n",
       " 'dor',\n",
       " '##nb',\n",
       " '##irn',\n",
       " 'hat',\n",
       " 'eine',\n",
       " '71',\n",
       " ',',\n",
       " '93',\n",
       " 'quadrat',\n",
       " '##meter',\n",
       " 'große',\n",
       " 'wohn',\n",
       " '##ung',\n",
       " 'fur',\n",
       " 'einen',\n",
       " 'quadrat',\n",
       " '##meter',\n",
       " '##preis',\n",
       " 'von',\n",
       " '55',\n",
       " '##33',\n",
       " ',',\n",
       " '71',\n",
       " 'eur',\n",
       " '##o',\n",
       " 'den',\n",
       " 'bes',\n",
       " '##itzer',\n",
       " 'gewechselt',\n",
       " '.',\n",
       " 'dieser',\n",
       " 'beinhaltet',\n",
       " 'auch',\n",
       " 'einen',\n",
       " 'p',\n",
       " '##kw',\n",
       " '-',\n",
       " 'abs',\n",
       " '##tell',\n",
       " '##platz',\n",
       " '.',\n",
       " 'kauf',\n",
       " '##er',\n",
       " 'der',\n",
       " 'wohn',\n",
       " '##ung',\n",
       " 'mit',\n",
       " '9',\n",
       " ',',\n",
       " '86',\n",
       " 'quadrat',\n",
       " '##metern',\n",
       " 'ter',\n",
       " '##rasse',\n",
       " 'ist',\n",
       " 'die',\n",
       " 'val',\n",
       " '##li',\n",
       " '##le',\n",
       " '##an',\n",
       " 'beteil',\n",
       " '##igungs',\n",
       " '-',\n",
       " 'und',\n",
       " 'imm',\n",
       " '##obilien',\n",
       " '##verwaltungs',\n",
       " 'g',\n",
       " '##mb',\n",
       " '##h',\n",
       " '.',\n",
       " 'beim',\n",
       " 'verkauf',\n",
       " '##er',\n",
       " 'handelt',\n",
       " 'es',\n",
       " 'sich',\n",
       " 'um',\n",
       " 'die',\n",
       " 'kar',\n",
       " '##ren',\n",
       " '##blick',\n",
       " 'pro',\n",
       " '##jekt',\n",
       " 'g',\n",
       " '##mb',\n",
       " '##h',\n",
       " '.',\n",
       " 'der',\n",
       " 'kauf',\n",
       " '##preis',\n",
       " 'liegt',\n",
       " 'bei',\n",
       " '39',\n",
       " '##8',\n",
       " '.',\n",
       " '04',\n",
       " '##0',\n",
       " 'eur',\n",
       " '##o',\n",
       " '.',\n",
       " 'unterzeichnet',\n",
       " 'wurde',\n",
       " 'der',\n",
       " 'kauf',\n",
       " '##vertrag',\n",
       " 'am',\n",
       " '18',\n",
       " '.',\n",
       " 'se',\n",
       " '##pt',\n",
       " '##ember',\n",
       " '.',\n",
       " 'die',\n",
       " 'verb',\n",
       " '##ucher',\n",
       " '##ung',\n",
       " 'datiert',\n",
       " 'mit',\n",
       " 'ok',\n",
       " '##to',\n",
       " '##ber',\n",
       " '2020',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1516c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            label = -100\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "        new_labels.append(label)\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed05db80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 'ORT', 'ORT', 'ORT', 'O', 'O', 'STRASSE', 'STRASSE', 'O', 'ORT', 'ORT', 'ORT', 'O', 'O', 'FLAECHE', 'FLAECHE', 'FLAECHE', 'O', 'O', 'O', 'IMMO_TYP', 'IMMO_TYP', 'O', 'O', 'O', 'O', 'O', 'O', 'QMPREIS', 'QMPREIS', 'QMPREIS', 'QMPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'TERRASSENGROESSE', 'TERRASSENGROESSE', 'TERRASSENGROESSE', 'O', 'O', 'O', 'O', 'O', 'O', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'KAEUFER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'VERKAEUFER', 'VERKAEUFER', 'VERKAEUFER', 'VERKAEUFER', 'VERKAEUFER', 'VERKAEUFER', 'VERKAEUFER', 'VERKAEUFER', 'VERKAEUFER', 'O', 'O', 'O', 'O', 'O', 'GESAMTPREIS', 'GESAMTPREIS', 'GESAMTPREIS', 'GESAMTPREIS', 'GESAMTPREIS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERTRAG', 'DATUM_VERTRAG', 'DATUM_VERTRAG', 'DATUM_VERTRAG', 'DATUM_VERTRAG', 'DATUM_VERTRAG', 'O', 'O', 'O', 'O', 'O', 'O', 'DATUM_VERBUECHERUNG', 'DATUM_VERBUECHERUNG', 'DATUM_VERBUECHERUNG', 'DATUM_VERBUECHERUNG', 'DATUM_VERBUECHERUNG', -100]\n",
      "134\n",
      "['[CLS]', 'dor', '##nb', '##irn', 'in', 'der', 'schul', '##gasse', 'in', 'dor', '##nb', '##irn', 'hat', 'eine', '71', ',', '93', 'quadrat', '##meter', 'große', 'wohn', '##ung', 'fur', 'einen', 'quadrat', '##meter', '##preis', 'von', '55', '##33', ',', '71', 'eur', '##o', 'den', 'bes', '##itzer', 'gewechselt', '.', 'dieser', 'beinhaltet', 'auch', 'einen', 'p', '##kw', '-', 'abs', '##tell', '##platz', '.', 'kauf', '##er', 'der', 'wohn', '##ung', 'mit', '9', ',', '86', 'quadrat', '##metern', 'ter', '##rasse', 'ist', 'die', 'val', '##li', '##le', '##an', 'beteil', '##igungs', '-', 'und', 'imm', '##obilien', '##verwaltungs', 'g', '##mb', '##h', '.', 'beim', 'verkauf', '##er', 'handelt', 'es', 'sich', 'um', 'die', 'kar', '##ren', '##blick', 'pro', '##jekt', 'g', '##mb', '##h', '.', 'der', 'kauf', '##preis', 'liegt', 'bei', '39', '##8', '.', '04', '##0', 'eur', '##o', '.', 'unterzeichnet', 'wurde', 'der', 'kauf', '##vertrag', 'am', '18', '.', 'se', '##pt', '##ember', '.', 'die', 'verb', '##ucher', '##ung', 'datiert', 'mit', 'ok', '##to', '##ber', '2020', '.', '[SEP]']\n",
      "134\n"
     ]
    }
   ],
   "source": [
    "labels = dataset[0][\"labels\"]\n",
    "word_ids = inputs.word_ids()\n",
    "aligned_labels = align_labels_with_tokens(labels, word_ids)\n",
    "print(aligned_labels)\n",
    "print(len(aligned_labels))\n",
    "print(inputs.tokens())\n",
    "print(len(inputs.tokens()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38d51b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.12.0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b3f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
