{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeab3c41",
   "metadata": {},
   "source": [
    "# Building a Huggingface `DatasetDict` for the *gNER* dataset\n",
    "**Tidy up and polish everything!**<br>\n",
    "The resulting dataset is stored in the folder *gNERdataset* and can be loaded via `load_from_disk(\"gNERdataset\")`. However, the `ClassLabel` list with the names of the NER tags is not available anymore when loading from disk!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "758a94ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instances:\n",
      "140\n",
      "\n",
      "all keys:\n",
      "['text', 'meta', '_input_hash', '_task_hash', 'spans', 'tokens', '_view_id', 'answer', '_timestamp']\n",
      "\n",
      "important keys:\n",
      "['text', 'spans', 'tokens']\n",
      "\n",
      "example text:\n",
      "DORNBIRN In der Schulgasse in Dornbirn hat eine 71,93 Quadratmeter große Wohnung für einen Quadratmeterpreis von 5533,71 Euro den Besitzer gewechselt. Dieser beinhaltet auch einen Pkw-Abstellplatz. Käufer der Wohnung mit 9,86 Quadratmetern Terrasse ist die ValLiLean Beteiligungs- und Immobilienverwaltungs GmbH. Beim Verkäufer handelt es sich um die Karrenblick Projekt GmbH.  Der Kaufpreis liegt bei 398.040 Euro. Unterzeichnet wurde der Kaufvertrag am 18. September. Die Verbücherung datiert mit Oktober 2020.\n",
      "\n",
      "5 example spans:\n",
      "{'text': 'DORNBIRN', 'start': 0, 'end': 8, 'pattern': 2069086582, 'token_start': 0, 'token_end': 0, 'label': 'ORT', 'noWords': 1}\n",
      "{'start': 16, 'end': 26, 'token_start': 3, 'token_end': 3, 'label': 'STRASSE', 'noWords': 1}\n",
      "{'text': 'Dornbirn', 'start': 30, 'end': 38, 'pattern': 2069086582, 'token_start': 5, 'token_end': 5, 'label': 'ORT', 'noWords': 1}\n",
      "{'start': 48, 'end': 53, 'token_start': 8, 'token_end': 8, 'label': 'FLAECHE', 'noWords': 1}\n",
      "{'start': 73, 'end': 80, 'token_start': 11, 'token_end': 11, 'label': 'IMMO_TYP', 'noWords': 1}\n",
      "\n",
      "5 example tokens:\n",
      "{'text': 'DORNBIRN', 'start': 0, 'end': 8, 'id': 0, 'ws': True, 'label': 'ORT'}\n",
      "{'text': 'In', 'start': 9, 'end': 11, 'id': 1, 'ws': True, 'label': 'O'}\n",
      "{'text': 'der', 'start': 12, 'end': 15, 'id': 2, 'ws': True, 'label': 'O'}\n",
      "{'text': 'Schulgasse', 'start': 16, 'end': 26, 'id': 3, 'ws': True, 'label': 'STRASSE'}\n",
      "{'text': 'in', 'start': 27, 'end': 29, 'id': 4, 'ws': True, 'label': 'O'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.utils import shuffle\n",
    "from datasets import Dataset\n",
    "from datasets import DatasetDict\n",
    "\n",
    "with open(\"./annotations2.jsonl\") as jsonl_file: # . instead of ..\n",
    "    lines = jsonl_file.readlines()\n",
    "annot = [json.loads(line) for line in lines]\n",
    "print(\"instances:\\n{}\".format(len(annot)))\n",
    "keys = [key for key in annot[0].keys()]\n",
    "print(\"\\nall keys:\\n{}\".format(keys))\n",
    "key_keys = [\"text\", \"spans\", \"tokens\"]\n",
    "print(\"\\nimportant keys:\\n{}\".format(key_keys))\n",
    "print(\"\\nexample text:\\n{}\".format(annot[0][\"text\"]))\n",
    "n_examples = 5\n",
    "print(\"\\n{} example spans:\".format(n_examples))\n",
    "for span in annot[0][\"spans\"][:n_examples]:\n",
    "    print(\"{}\".format(span))\n",
    "print(\"\\n{} example tokens:\".format(n_examples))\n",
    "for token in annot[0][\"tokens\"][:n_examples]:\n",
    "    print(\"{}\".format(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc53d613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token dictionaries for the last 3 words of instance 0\n",
      "{'text': 'DORNBIRN', 'start': 0, 'end': 8, 'id': 0, 'ws': True, 'label': 'ORT'}\n",
      "{'text': 'In', 'start': 9, 'end': 11, 'id': 1, 'ws': True, 'label': 'O'}\n",
      "{'text': 'der', 'start': 12, 'end': 15, 'id': 2, 'ws': True, 'label': 'O'}\n",
      "Token dictionaries for the last 3 words of instance 1\n",
      "{'text': 'FELDKIRCH', 'start': 0, 'end': 9, 'id': 0, 'ws': True, 'label': 'ORT'}\n",
      "{'text': 'Im', 'start': 10, 'end': 12, 'id': 1, 'ws': True, 'label': 'O'}\n",
      "{'text': 'Altenreuteweg', 'start': 13, 'end': 26, 'id': 2, 'ws': True, 'label': 'STRASSE'}\n"
     ]
    }
   ],
   "source": [
    "def getLabel(tokenDictList, idx):\n",
    "    result = \"O\"\n",
    "    for dict_i in tokenDictList:\n",
    "        idx_0, idx_1 = dict_i[\"start\"], dict_i[\"end\"]\n",
    "        if (idx_0<=idx) and (idx<=idx_1):\n",
    "            result = dict_i[\"label\"]\n",
    "    return result \n",
    "\n",
    "for j in range(len(annot)): # loop over instances\n",
    "    a = annot[j]            # instance j\n",
    "    spans = a[\"spans\"]      # list of annotation dicts\n",
    "    toks = a[\"tokens\"]      # list of token dicts\n",
    "    for i in range(len(toks)):                                 # loop over token dicts\n",
    "        toks[i][\"label\"] = getLabel(spans, toks[i][\"start\"])   # assign label from span (if exists, otherwise \"O\")\n",
    "    annot[j][\"tokens\"] = toks\n",
    "\n",
    "words_n = 3\n",
    "for i in range(2):\n",
    "    print(\"Token dictionaries for the last {} words of instance {}\".format(words_n, i))\n",
    "    ann = annot[i]\n",
    "    for tok in ann[\"tokens\"][:words_n]:\n",
    "        print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e587b7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('DORNBIRN', 'ORT'),\n",
       "  ('In', 'O'),\n",
       "  ('der', 'O'),\n",
       "  ('Schulgasse', 'STRASSE'),\n",
       "  ('in', 'O'),\n",
       "  ('Dornbirn', 'ORT'),\n",
       "  ('hat', 'O'),\n",
       "  ('eine', 'O'),\n",
       "  ('71,93', 'FLAECHE'),\n",
       "  ('Quadratmeter', 'O'),\n",
       "  ('große', 'O'),\n",
       "  ('Wohnung', 'IMMO_TYP'),\n",
       "  ('für', 'O'),\n",
       "  ('einen', 'O'),\n",
       "  ('Quadratmeterpreis', 'O'),\n",
       "  ('von', 'O'),\n",
       "  ('5533,71', 'QMPREIS'),\n",
       "  ('Euro', 'O'),\n",
       "  ('den', 'O'),\n",
       "  ('Besitzer', 'O'),\n",
       "  ('gewechselt', 'O'),\n",
       "  ('.', 'O'),\n",
       "  ('Dieser', 'O'),\n",
       "  ('beinhaltet', 'O'),\n",
       "  ('auch', 'O'),\n",
       "  ('einen', 'O'),\n",
       "  ('Pkw-Abstellplatz', 'O'),\n",
       "  ('.', 'O'),\n",
       "  ('Käufer', 'O'),\n",
       "  ('der', 'O'),\n",
       "  ('Wohnung', 'O'),\n",
       "  ('mit', 'O'),\n",
       "  ('9,86', 'TERRASSENGROESSE'),\n",
       "  ('Quadratmetern', 'O'),\n",
       "  ('Terrasse', 'O'),\n",
       "  ('ist', 'O'),\n",
       "  ('die', 'O'),\n",
       "  ('ValLiLean', 'KAEUFER'),\n",
       "  ('Beteiligungs-', 'KAEUFER'),\n",
       "  ('und', 'KAEUFER'),\n",
       "  ('Immobilienverwaltungs', 'KAEUFER'),\n",
       "  ('GmbH', 'KAEUFER'),\n",
       "  ('.', 'KAEUFER'),\n",
       "  ('Beim', 'O'),\n",
       "  ('Verkäufer', 'O'),\n",
       "  ('handelt', 'O'),\n",
       "  ('es', 'O'),\n",
       "  ('sich', 'O'),\n",
       "  ('um', 'O'),\n",
       "  ('die', 'O'),\n",
       "  ('Karrenblick', 'VERKAEUFER'),\n",
       "  ('Projekt', 'VERKAEUFER'),\n",
       "  ('GmbH', 'VERKAEUFER'),\n",
       "  ('.', 'VERKAEUFER'),\n",
       "  (' ', 'O'),\n",
       "  ('Der', 'O'),\n",
       "  ('Kaufpreis', 'O'),\n",
       "  ('liegt', 'O'),\n",
       "  ('bei', 'O'),\n",
       "  ('398.040', 'GESAMTPREIS'),\n",
       "  ('Euro', 'O'),\n",
       "  ('.', 'O'),\n",
       "  ('Unterzeichnet', 'O'),\n",
       "  ('wurde', 'O'),\n",
       "  ('der', 'O'),\n",
       "  ('Kaufvertrag', 'O'),\n",
       "  ('am', 'O'),\n",
       "  ('18.', 'DATUM_VERTRAG'),\n",
       "  ('September', 'DATUM_VERTRAG'),\n",
       "  ('.', 'DATUM_VERTRAG'),\n",
       "  ('Die', 'O'),\n",
       "  ('Verbücherung', 'O'),\n",
       "  ('datiert', 'O'),\n",
       "  ('mit', 'O'),\n",
       "  ('Oktober', 'DATUM_VERBUECHERUNG'),\n",
       "  ('2020', 'DATUM_VERBUECHERUNG'),\n",
       "  ('.', 'DATUM_VERBUECHERUNG')],\n",
       " [('FELDKIRCH', 'ORT'),\n",
       "  ('Im', 'O'),\n",
       "  ('Altenreuteweg', 'STRASSE'),\n",
       "  ('in', 'O'),\n",
       "  ('Feldkirch', 'ORT'),\n",
       "  ('hat', 'O'),\n",
       "  ('eine', 'O'),\n",
       "  ('100,67', 'FLAECHE'),\n",
       "  ('Quadratmeter', 'O'),\n",
       "  ('große', 'O'),\n",
       "  ('Wohnung', 'IMMO_TYP'),\n",
       "  ('für', 'O'),\n",
       "  ('einen', 'O'),\n",
       "  ('Quadratmeterpreis', 'O'),\n",
       "  ('von', 'O'),\n",
       "  ('6168,67', 'QMPREIS'),\n",
       "  ('Euro', 'O'),\n",
       "  ('den', 'O'),\n",
       "  ('Besitzer', 'O'),\n",
       "  ('gewechselt', 'O'),\n",
       "  ('.', 'O'),\n",
       "  ('Käufer', 'O'),\n",
       "  ('der', 'O'),\n",
       "  ('Wohnung', 'O'),\n",
       "  ('mit', 'O'),\n",
       "  ('einer', 'O'),\n",
       "  ('137,49', 'TERRASSENGROESSE'),\n",
       "  ('Quadratmeter', 'O'),\n",
       "  ('großen', 'O'),\n",
       "  ('Terrasse', 'O'),\n",
       "  ('ist', 'O'),\n",
       "  ('eine', 'O'),\n",
       "  ('Privatperson', 'KAEUFER'),\n",
       "  ('.', 'KAEUFER'),\n",
       "  ('Beim', 'O'),\n",
       "  ('Verkäufer', 'O'),\n",
       "  ('handelt', 'O'),\n",
       "  ('es', 'O'),\n",
       "  ('sich', 'O'),\n",
       "  ('um', 'O'),\n",
       "  ('die', 'O'),\n",
       "  ('Rüscher', 'VERKAEUFER'),\n",
       "  ('und', 'VERKAEUFER'),\n",
       "  ('Söhne', 'VERKAEUFER'),\n",
       "  ('Bau', 'VERKAEUFER'),\n",
       "  ('GmbH', 'VERKAEUFER'),\n",
       "  ('&', 'VERKAEUFER'),\n",
       "  ('Co', 'VERKAEUFER'),\n",
       "  ('KG', 'VERKAEUFER'),\n",
       "  ('.', 'VERKAEUFER'),\n",
       "  (' ', 'O'),\n",
       "  ('Der', 'O'),\n",
       "  ('Kaufpreis', 'O'),\n",
       "  ('liegt', 'O'),\n",
       "  ('bei', 'O'),\n",
       "  ('621.000', 'GESAMTPREIS'),\n",
       "  ('Euro', 'O'),\n",
       "  ('.', 'O'),\n",
       "  ('Unterzeichnet', 'O'),\n",
       "  ('wurde', 'O'),\n",
       "  ('der', 'O'),\n",
       "  ('Kaufvertrag', 'O'),\n",
       "  ('am', 'O'),\n",
       "  ('11.', 'DATUM_VERTRAG'),\n",
       "  ('August', 'DATUM_VERTRAG'),\n",
       "  ('.', 'DATUM_VERTRAG'),\n",
       "  ('Die', 'O'),\n",
       "  ('Verbücherung', 'O'),\n",
       "  ('datiert', 'O'),\n",
       "  ('mit', 'O'),\n",
       "  ('September', 'DATUM_VERBUECHERUNG'),\n",
       "  ('2020', 'DATUM_VERBUECHERUNG'),\n",
       "  ('.', 'DATUM_VERBUECHERUNG')]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents=[] \n",
    "for annot_i in annot:                  # loop over instances\n",
    "    toks = annot_i['tokens']           # get tokens list for instance i\n",
    "    train_sentence = []\n",
    "    for tok in toks:                   # loop over token dicts\n",
    "        if 'label' in tok:             # only if the current token has been labelled, ...\n",
    "            token_element = (tok['text'], tok['label']) # ... create a \"text\", \"label\" pair for this token ...\n",
    "            train_sentence.append(token_element)        # ... and append it to the list\n",
    "    sents.append(train_sentence) # append the list for that instances to the list for all instances / sentences\n",
    "\n",
    "# list of lists of pairs (sets): outer list contains instances and inner list contains (token, label) pairs\n",
    "sents[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec2593d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 140)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. build tokens = list of lists of tokens\n",
    "# 2. build labels = list of lists of labels\n",
    "words = []\n",
    "ner_tags = []\n",
    "for sent_i in sents:\n",
    "    words_i = []\n",
    "    ner_tags_i = []\n",
    "    for item in sent_i:\n",
    "        words_i.append(item[0])\n",
    "        ner_tags_i.append(item[1])\n",
    "    words.append(words_i)\n",
    "    ner_tags.append(ner_tags_i)\n",
    "\n",
    "len(words), len(ner_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95a02564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[45, 59, 7, 50, 92]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(104, 104, 36, 36)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratio = 0.75\n",
    "train_test_split = round(0.75*len(words) - 0.5) # -0.5 => floor\n",
    "idx = [i for i in range(len(words))]\n",
    "print(idx[:5])\n",
    "idx_shuffle = shuffle(idx, random_state=0)\n",
    "print(idx_shuffle[:5])\n",
    "words_shuffle, ner_tags_shuffle = [words[idx_i] for idx_i in idx_shuffle], [ner_tags[idx_i] for idx_i in idx_shuffle]\n",
    "words_train, words_test = words_shuffle[:train_test_split], words_shuffle[train_test_split:]\n",
    "ner_tags_train, ner_tags_test = ner_tags_shuffle[:train_test_split], ner_tags_shuffle[train_test_split:]\n",
    "len(words_train), len(ner_tags_train), len(words_test), len(ner_tags_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76e405d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['words', 'ner_tags'],\n",
       "        num_rows: 78\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['words', 'ner_tags'],\n",
       "        num_rows: 26\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['words', 'ner_tags'],\n",
       "        num_rows: 36\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_dict({\"words\": words_train, \"ner_tags\": ner_tags_train})\n",
    "test_dataset = Dataset.from_dict({\"words\": words_test, \"ner_tags\": ner_tags_test})\n",
    "train_valid_split = train_dataset.train_test_split(shuffle=True, seed=42, test_size=0.25)\n",
    "untokenizedDatasetDict = DatasetDict({\n",
    "    \"train\": train_valid_split[\"train\"],\n",
    "    \"valid\": train_valid_split[\"test\"],\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "untokenizedDatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8287f437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DATUM_VERBUECHERUNG',\n",
       " 'DATUM_VERTRAG',\n",
       " 'FLAECHE',\n",
       " 'GESAMTPREIS',\n",
       " 'IMMO_TYP',\n",
       " 'KAEUFER',\n",
       " 'O',\n",
       " 'ORT',\n",
       " 'QMPREIS',\n",
       " 'STRASSE',\n",
       " 'TERRASSENGROESSE',\n",
       " 'VERKAEUFER']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set of labels\n",
    "ner_tag_names = sorted(list(set([ner_tag_ij for ner_tags_i in ner_tags for ner_tag_ij in ner_tags_i])))\n",
    "ner_tag_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11feed58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize and adjust labels\n",
    "from transformers import AutoTokenizer\n",
    "checkpoint = \"flair/ner-german\"  # https://huggingface.co/flair/ner-german (1.41GB)\n",
    "checkpoint = \"fhswf/bert_de_ner\" # https://huggingface.co/fhswf/bert_de_ner (419MB)\n",
    "checkpoint = \"bert-base-cased\"   # https://huggingface.co/bert-base-cased (416MB)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e12daac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0\ttoken: [CLS]\tword_id: None\taligned label: -100\ttext label: SPECIAL TOKEN\n",
      "index: 1\ttoken: L\tword_id: 0\taligned label: 7\ttext label: ORT\n",
      "index: 2\ttoken: ##US\tword_id: 0\taligned label: 7\ttext label: ORT\n",
      "index: 3\ttoken: ##TE\tword_id: 0\taligned label: 7\ttext label: ORT\n",
      "index: 4\ttoken: ##NA\tword_id: 0\taligned label: 7\ttext label: ORT\n",
      "index: 5\ttoken: ##U\tword_id: 0\taligned label: 7\ttext label: ORT\n",
      "index: 6\ttoken: In\tword_id: 1\taligned label: 6\ttext label: O\n",
      "index: 7\ttoken: der\tword_id: 2\taligned label: 6\ttext label: O\n",
      "index: 8\ttoken: Stein\tword_id: 3\taligned label: 9\ttext label: STRASSE\n",
      "index: 9\ttoken: ##ack\tword_id: 3\taligned label: 9\ttext label: STRASSE\n",
      "index: 10\ttoken: ##ers\tword_id: 3\taligned label: 9\ttext label: STRASSE\n",
      "index: 11\ttoken: ##tra\tword_id: 3\taligned label: 9\ttext label: STRASSE\n",
      "index: 12\ttoken: ##ße\tword_id: 3\taligned label: 9\ttext label: STRASSE\n",
      "index: 13\ttoken: 26\tword_id: 4\taligned label: 9\ttext label: STRASSE\n",
      "index: 14\ttoken: in\tword_id: 5\taligned label: 6\ttext label: O\n",
      "index: 15\ttoken: Lu\tword_id: 6\taligned label: 7\ttext label: ORT\n",
      "index: 16\ttoken: ##sten\tword_id: 6\taligned label: 7\ttext label: ORT\n",
      "index: 17\ttoken: ##au\tword_id: 6\taligned label: 7\ttext label: ORT\n",
      "index: 18\ttoken: hat\tword_id: 7\taligned label: 6\ttext label: O\n",
      "index: 19\ttoken: e\tword_id: 8\taligned label: 6\ttext label: O\n",
      "index: 20\ttoken: ##ine\tword_id: 8\taligned label: 6\ttext label: O\n",
      "index: 21\ttoken: 93\tword_id: 9\taligned label: 2\ttext label: FLAECHE\n",
      "index: 22\ttoken: ,\tword_id: 9\taligned label: 2\ttext label: FLAECHE\n",
      "index: 23\ttoken: 8\tword_id: 9\taligned label: 2\ttext label: FLAECHE\n",
      "index: 24\ttoken: Q\tword_id: 10\taligned label: 6\ttext label: O\n",
      "index: 25\ttoken: ##uad\tword_id: 10\taligned label: 6\ttext label: O\n",
      "index: 26\ttoken: ##rat\tword_id: 10\taligned label: 6\ttext label: O\n",
      "index: 27\ttoken: ##meter\tword_id: 10\taligned label: 6\ttext label: O\n",
      "index: 28\ttoken: g\tword_id: 11\taligned label: 6\ttext label: O\n",
      "index: 29\ttoken: ##ro\tword_id: 11\taligned label: 6\ttext label: O\n",
      "index: 30\ttoken: ##ße\tword_id: 11\taligned label: 6\ttext label: O\n",
      "index: 31\ttoken: W\tword_id: 12\taligned label: 4\ttext label: IMMO_TYP\n",
      "index: 32\ttoken: ##oh\tword_id: 12\taligned label: 4\ttext label: IMMO_TYP\n",
      "index: 33\ttoken: ##nu\tword_id: 12\taligned label: 4\ttext label: IMMO_TYP\n",
      "index: 34\ttoken: ##ng\tword_id: 12\taligned label: 4\ttext label: IMMO_TYP\n",
      "index: 35\ttoken: für\tword_id: 13\taligned label: 6\ttext label: O\n",
      "index: 36\ttoken: e\tword_id: 14\taligned label: 6\ttext label: O\n",
      "index: 37\ttoken: ##inen\tword_id: 14\taligned label: 6\ttext label: O\n",
      "index: 38\ttoken: Q\tword_id: 15\taligned label: 6\ttext label: O\n",
      "index: 39\ttoken: ##uad\tword_id: 15\taligned label: 6\ttext label: O\n",
      "index: 40\ttoken: ##rat\tword_id: 15\taligned label: 6\ttext label: O\n",
      "index: 41\ttoken: ##meter\tword_id: 15\taligned label: 6\ttext label: O\n",
      "index: 42\ttoken: ##p\tword_id: 15\taligned label: 6\ttext label: O\n",
      "index: 43\ttoken: ##reis\tword_id: 15\taligned label: 6\ttext label: O\n",
      "index: 44\ttoken: von\tword_id: 16\taligned label: 6\ttext label: O\n",
      "index: 45\ttoken: 45\tword_id: 17\taligned label: 8\ttext label: QMPREIS\n",
      "index: 46\ttoken: ##8\tword_id: 17\taligned label: 8\ttext label: QMPREIS\n",
      "index: 47\ttoken: ##4\tword_id: 17\taligned label: 8\ttext label: QMPREIS\n",
      "index: 48\ttoken: ,\tword_id: 17\taligned label: 8\ttext label: QMPREIS\n",
      "index: 49\ttoken: 22\tword_id: 17\taligned label: 8\ttext label: QMPREIS\n",
      "index: 50\ttoken: Euro\tword_id: 18\taligned label: 6\ttext label: O\n",
      "index: 51\ttoken: den\tword_id: 19\taligned label: 6\ttext label: O\n",
      "index: 52\ttoken: Be\tword_id: 20\taligned label: 6\ttext label: O\n",
      "index: 53\ttoken: ##si\tword_id: 20\taligned label: 6\ttext label: O\n",
      "index: 54\ttoken: ##tz\tword_id: 20\taligned label: 6\ttext label: O\n",
      "index: 55\ttoken: ##er\tword_id: 20\taligned label: 6\ttext label: O\n",
      "index: 56\ttoken: g\tword_id: 21\taligned label: 6\ttext label: O\n",
      "index: 57\ttoken: ##ew\tword_id: 21\taligned label: 6\ttext label: O\n",
      "index: 58\ttoken: ##ech\tword_id: 21\taligned label: 6\ttext label: O\n",
      "index: 59\ttoken: ##sel\tword_id: 21\taligned label: 6\ttext label: O\n",
      "index: 60\ttoken: ##t\tword_id: 21\taligned label: 6\ttext label: O\n",
      "index: 61\ttoken: .\tword_id: 22\taligned label: 6\ttext label: O\n",
      "index: 62\ttoken: Die\tword_id: 23\taligned label: 6\ttext label: O\n",
      "index: 63\ttoken: ##ser\tword_id: 23\taligned label: 6\ttext label: O\n",
      "index: 64\ttoken: be\tword_id: 24\taligned label: 6\ttext label: O\n",
      "index: 65\ttoken: ##in\tword_id: 24\taligned label: 6\ttext label: O\n",
      "index: 66\ttoken: ##halt\tword_id: 24\taligned label: 6\ttext label: O\n",
      "index: 67\ttoken: ##et\tword_id: 24\taligned label: 6\ttext label: O\n",
      "index: 68\ttoken: au\tword_id: 25\taligned label: 6\ttext label: O\n",
      "index: 69\ttoken: ##ch\tword_id: 25\taligned label: 6\ttext label: O\n",
      "index: 70\ttoken: e\tword_id: 26\taligned label: 6\ttext label: O\n",
      "index: 71\ttoken: ##inen\tword_id: 26\taligned label: 6\ttext label: O\n",
      "index: 72\ttoken: P\tword_id: 27\taligned label: 6\ttext label: O\n",
      "index: 73\ttoken: ##k\tword_id: 27\taligned label: 6\ttext label: O\n",
      "index: 74\ttoken: ##w\tword_id: 27\taligned label: 6\ttext label: O\n",
      "index: 75\ttoken: -\tword_id: 27\taligned label: 6\ttext label: O\n",
      "index: 76\ttoken: A\tword_id: 27\taligned label: 6\ttext label: O\n",
      "index: 77\ttoken: ##bs\tword_id: 27\taligned label: 6\ttext label: O\n",
      "index: 78\ttoken: ##tel\tword_id: 27\taligned label: 6\ttext label: O\n",
      "index: 79\ttoken: ##l\tword_id: 27\taligned label: 6\ttext label: O\n",
      "index: 80\ttoken: ##p\tword_id: 27\taligned label: 6\ttext label: O\n",
      "index: 81\ttoken: ##latz\tword_id: 27\taligned label: 6\ttext label: O\n",
      "index: 82\ttoken: .\tword_id: 28\taligned label: 6\ttext label: O\n",
      "index: 83\ttoken: Be\tword_id: 29\taligned label: 6\ttext label: O\n",
      "index: 84\ttoken: ##i\tword_id: 29\taligned label: 6\ttext label: O\n",
      "index: 85\ttoken: K\tword_id: 30\taligned label: 6\ttext label: O\n",
      "index: 86\ttoken: ##ä\tword_id: 30\taligned label: 6\ttext label: O\n",
      "index: 87\ttoken: ##uf\tword_id: 30\taligned label: 6\ttext label: O\n",
      "index: 88\ttoken: ##er\tword_id: 30\taligned label: 6\ttext label: O\n",
      "index: 89\ttoken: und\tword_id: 31\taligned label: 6\ttext label: O\n",
      "index: 90\ttoken: V\tword_id: 32\taligned label: 6\ttext label: O\n",
      "index: 91\ttoken: ##er\tword_id: 32\taligned label: 6\ttext label: O\n",
      "index: 92\ttoken: ##k\tword_id: 32\taligned label: 6\ttext label: O\n",
      "index: 93\ttoken: ##ä\tword_id: 32\taligned label: 6\ttext label: O\n",
      "index: 94\ttoken: ##uf\tword_id: 32\taligned label: 6\ttext label: O\n",
      "index: 95\ttoken: ##er\tword_id: 32\taligned label: 6\ttext label: O\n",
      "index: 96\ttoken: der\tword_id: 33\taligned label: 6\ttext label: O\n",
      "index: 97\ttoken: W\tword_id: 34\taligned label: 6\ttext label: O\n",
      "index: 98\ttoken: ##oh\tword_id: 34\taligned label: 6\ttext label: O\n",
      "index: 99\ttoken: ##nu\tword_id: 34\taligned label: 6\ttext label: O\n",
      "index: 100\ttoken: ##ng\tword_id: 34\taligned label: 6\ttext label: O\n",
      "index: 101\ttoken: mit\tword_id: 35\taligned label: 6\ttext label: O\n",
      "index: 102\ttoken: 22\tword_id: 36\taligned label: 10\ttext label: TERRASSENGROESSE\n",
      "index: 103\ttoken: ,\tword_id: 36\taligned label: 10\ttext label: TERRASSENGROESSE\n",
      "index: 104\ttoken: 26\tword_id: 36\taligned label: 10\ttext label: TERRASSENGROESSE\n",
      "index: 105\ttoken: Q\tword_id: 37\taligned label: 6\ttext label: O\n",
      "index: 106\ttoken: ##uad\tword_id: 37\taligned label: 6\ttext label: O\n",
      "index: 107\ttoken: ##rat\tword_id: 37\taligned label: 6\ttext label: O\n",
      "index: 108\ttoken: ##meter\tword_id: 37\taligned label: 6\ttext label: O\n",
      "index: 109\ttoken: ##n\tword_id: 37\taligned label: 6\ttext label: O\n",
      "index: 110\ttoken: Terra\tword_id: 38\taligned label: 6\ttext label: O\n",
      "index: 111\ttoken: ##sse\tword_id: 38\taligned label: 6\ttext label: O\n",
      "index: 112\ttoken: hand\tword_id: 39\taligned label: 6\ttext label: O\n",
      "index: 113\ttoken: ##el\tword_id: 39\taligned label: 6\ttext label: O\n",
      "index: 114\ttoken: ##t\tword_id: 39\taligned label: 6\ttext label: O\n",
      "index: 115\ttoken: es\tword_id: 40\taligned label: 6\ttext label: O\n",
      "index: 116\ttoken: sic\tword_id: 41\taligned label: 6\ttext label: O\n",
      "index: 117\ttoken: ##h\tword_id: 41\taligned label: 6\ttext label: O\n",
      "index: 118\ttoken: um\tword_id: 42\taligned label: 6\ttext label: O\n",
      "index: 119\ttoken: P\tword_id: 43\taligned label: 11\ttext label: VERKAEUFER\n",
      "index: 120\ttoken: ##ri\tword_id: 43\taligned label: 11\ttext label: VERKAEUFER\n",
      "index: 121\ttoken: ##vat\tword_id: 43\taligned label: 11\ttext label: VERKAEUFER\n",
      "index: 122\ttoken: ##person\tword_id: 43\taligned label: 11\ttext label: VERKAEUFER\n",
      "index: 123\ttoken: ##en\tword_id: 43\taligned label: 11\ttext label: VERKAEUFER\n",
      "index: 124\ttoken: .\tword_id: 44\taligned label: 11\ttext label: VERKAEUFER\n",
      "index: 125\ttoken: Der\tword_id: 45\taligned label: 6\ttext label: O\n",
      "index: 126\ttoken: Ka\tword_id: 46\taligned label: 6\ttext label: O\n",
      "index: 127\ttoken: ##uf\tword_id: 46\taligned label: 6\ttext label: O\n",
      "index: 128\ttoken: ##p\tword_id: 46\taligned label: 6\ttext label: O\n",
      "index: 129\ttoken: ##reis\tword_id: 46\taligned label: 6\ttext label: O\n",
      "index: 130\ttoken: lie\tword_id: 47\taligned label: 6\ttext label: O\n",
      "index: 131\ttoken: ##gt\tword_id: 47\taligned label: 6\ttext label: O\n",
      "index: 132\ttoken: be\tword_id: 48\taligned label: 6\ttext label: O\n",
      "index: 133\ttoken: ##i\tword_id: 48\taligned label: 6\ttext label: O\n",
      "index: 134\ttoken: 430\tword_id: 49\taligned label: 3\ttext label: GESAMTPREIS\n",
      "index: 135\ttoken: .\tword_id: 49\taligned label: 3\ttext label: GESAMTPREIS\n",
      "index: 136\ttoken: 000\tword_id: 49\taligned label: 3\ttext label: GESAMTPREIS\n",
      "index: 137\ttoken: Euro\tword_id: 50\taligned label: 6\ttext label: O\n",
      "index: 138\ttoken: .\tword_id: 51\taligned label: 6\ttext label: O\n",
      "index: 139\ttoken: Un\tword_id: 52\taligned label: 6\ttext label: O\n",
      "index: 140\ttoken: ##ter\tword_id: 52\taligned label: 6\ttext label: O\n",
      "index: 141\ttoken: ##ze\tword_id: 52\taligned label: 6\ttext label: O\n",
      "index: 142\ttoken: ##ich\tword_id: 52\taligned label: 6\ttext label: O\n",
      "index: 143\ttoken: ##net\tword_id: 52\taligned label: 6\ttext label: O\n",
      "index: 144\ttoken: w\tword_id: 53\taligned label: 6\ttext label: O\n",
      "index: 145\ttoken: ##ur\tword_id: 53\taligned label: 6\ttext label: O\n",
      "index: 146\ttoken: ##de\tword_id: 53\taligned label: 6\ttext label: O\n",
      "index: 147\ttoken: der\tword_id: 54\taligned label: 6\ttext label: O\n",
      "index: 148\ttoken: Ka\tword_id: 55\taligned label: 6\ttext label: O\n",
      "index: 149\ttoken: ##uf\tword_id: 55\taligned label: 6\ttext label: O\n",
      "index: 150\ttoken: ##vert\tword_id: 55\taligned label: 6\ttext label: O\n",
      "index: 151\ttoken: ##rag\tword_id: 55\taligned label: 6\ttext label: O\n",
      "index: 152\ttoken: am\tword_id: 56\taligned label: 6\ttext label: O\n",
      "index: 153\ttoken: 6\tword_id: 57\taligned label: 1\ttext label: DATUM_VERTRAG\n",
      "index: 154\ttoken: .\tword_id: 57\taligned label: 1\ttext label: DATUM_VERTRAG\n",
      "index: 155\ttoken: Jul\tword_id: 58\taligned label: 1\ttext label: DATUM_VERTRAG\n",
      "index: 156\ttoken: ##i\tword_id: 58\taligned label: 1\ttext label: DATUM_VERTRAG\n",
      "index: 157\ttoken: .\tword_id: 59\taligned label: 1\ttext label: DATUM_VERTRAG\n",
      "index: 158\ttoken: Die\tword_id: 60\taligned label: 6\ttext label: O\n",
      "index: 159\ttoken: V\tword_id: 61\taligned label: 6\ttext label: O\n",
      "index: 160\ttoken: ##er\tword_id: 61\taligned label: 6\ttext label: O\n",
      "index: 161\ttoken: ##b\tword_id: 61\taligned label: 6\ttext label: O\n",
      "index: 162\ttoken: ##ü\tword_id: 61\taligned label: 6\ttext label: O\n",
      "index: 163\ttoken: ##cher\tword_id: 61\taligned label: 6\ttext label: O\n",
      "index: 164\ttoken: ##ung\tword_id: 61\taligned label: 6\ttext label: O\n",
      "index: 165\ttoken: da\tword_id: 62\taligned label: 6\ttext label: O\n",
      "index: 166\ttoken: ##tier\tword_id: 62\taligned label: 6\ttext label: O\n",
      "index: 167\ttoken: ##t\tword_id: 62\taligned label: 6\ttext label: O\n",
      "index: 168\ttoken: mit\tword_id: 63\taligned label: 6\ttext label: O\n",
      "index: 169\ttoken: J\tword_id: 64\taligned label: 0\ttext label: DATUM_VERBUECHERUNG\n",
      "index: 170\ttoken: ##ä\tword_id: 64\taligned label: 0\ttext label: DATUM_VERBUECHERUNG\n",
      "index: 171\ttoken: ##nner\tword_id: 64\taligned label: 0\ttext label: DATUM_VERBUECHERUNG\n",
      "index: 172\ttoken: 202\tword_id: 65\taligned label: 0\ttext label: DATUM_VERBUECHERUNG\n",
      "index: 173\ttoken: ##1\tword_id: 65\taligned label: 0\ttext label: DATUM_VERBUECHERUNG\n",
      "index: 174\ttoken: .\tword_id: 66\taligned label: 0\ttext label: DATUM_VERBUECHERUNG\n",
      "index: 175\ttoken: [SEP]\tword_id: None\taligned label: -100\ttext label: SPECIAL TOKEN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(176, 176, 176)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def align_labels_with_tokens(ner_tags, word_ids):\n",
    "    #print(word_ids)\n",
    "    new_labels = []\n",
    "    previous_label = None\n",
    "    previous_word_id = None\n",
    "    for word_id in word_ids:\n",
    "        # handle word_id==None\n",
    "        if word_id==None:\n",
    "            label = -100\n",
    "        # handle word_id==previous_word_id\n",
    "        elif word_id==previous_word_id:\n",
    "            label = previous_label\n",
    "        # handle word_id!=previous_word_id and word_id!=None\n",
    "        else:\n",
    "            text_label = ner_tags[word_id]\n",
    "            label = ner_tag_names.index(text_label)\n",
    "        new_labels.append(label)\n",
    "        previous_label = label\n",
    "        previous_word_id = word_id\n",
    "    return new_labels\n",
    "\n",
    "instance = 0\n",
    "ner_tags = untokenizedDatasetDict[\"train\"][instance][\"ner_tags\"]\n",
    "word_ids = tokenizer(untokenizedDatasetDict[\"train\"][instance][\"words\"], is_split_into_words=True).word_ids()\n",
    "aligned_labels = align_labels_with_tokens(ner_tags, word_ids)\n",
    "inputs = tokenizer(untokenizedDatasetDict[\"train\"][instance][\"words\"], is_split_into_words=True)\n",
    "for i, token in enumerate(inputs.tokens()):\n",
    "    alabel = aligned_labels[i]\n",
    "    tlabel = ner_tag_names[alabel] if alabel>=0 else \"SPECIAL TOKEN\"\n",
    "    print(f\"index: {i}\\ttoken: {token}\\tword_id: {word_ids[i]}\\taligned label: {alabel}\\ttext label: {tlabel}\")\n",
    "len(inputs.tokens()), len(aligned_labels), len(word_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "015cb92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0f26accc8d47768a4807054564b139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d3244e0a0c4f2089e7ad9fe41e70e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d1be7f26b54b60952d2276715ba0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 78\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 26\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 36\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"words\"], truncation=True, is_split_into_words=True)\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs\n",
    "#\n",
    "gNerDatasetDict = untokenizedDatasetDict.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=untokenizedDatasetDict[\"train\"].column_names\n",
    ")\n",
    "gNerDatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "733a6c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabel(num_classes=12, names=['DATUM_VERBUECHERUNG', 'DATUM_VERTRAG', 'FLAECHE', 'GESAMTPREIS', 'IMMO_TYP', 'KAEUFER', 'O', 'ORT', 'QMPREIS', 'STRASSE', 'TERRASSENGROESSE', 'VERKAEUFER'], id=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['DATUM_VERBUECHERUNG',\n",
       " 'DATUM_VERTRAG',\n",
       " 'FLAECHE',\n",
       " 'GESAMTPREIS',\n",
       " 'IMMO_TYP',\n",
       " 'KAEUFER',\n",
       " 'O',\n",
       " 'ORT',\n",
       " 'QMPREIS',\n",
       " 'STRASSE',\n",
       " 'TERRASSENGROESSE',\n",
       " 'VERKAEUFER']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import ClassLabel\n",
    "gNerDatasetDict[\"train\"].features[\"labels\"].feature.names = ClassLabel(names=ner_tag_names)\n",
    "print(gNerDatasetDict[\"train\"].features[\"labels\"].feature.names)\n",
    "gNerDatasetDict[\"train\"].features[\"labels\"].feature.names.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc4ed0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gNerDatasetDict.save_to_disk(\"gNERdataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd634308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 78\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 26\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 36\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "gNerDatasetCheck = load_from_disk(\"gNERdataset\")\n",
    "# Note, however, that the \"ClassLabel\" list with the names of the NER tags is not available, anymore!\n",
    "gNerDatasetCheck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5efaa",
   "metadata": {},
   "source": [
    "$\\checkmark$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
